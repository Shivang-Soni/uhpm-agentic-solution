import json
import logging

from llm.gemini_pipeline import invoke
from vectorstore.store import add_document

# Logging configuration
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ExperimentationAgent:
    """
    A/B Testing + Variant Scoring Agent
    Scores multiple content variants and returns the best performer.
    """

    def __init__(self):
        pass

    def score_variants(
            self, persona_text: str, channel: str, variants: list[str]
            ) -> dict:
        """
        Scores content variants based on persona fit and conversion likelihood.
        """

        prompt = f"""
        You are an AI MARKETING EXPERIMENT EVAULATOR.
        Score each content variant from 0 to 100 based on:

        - Fit to Persona
        - Fit to Channel
        - Conversion Likelihood
        - Clarity and persuasiveness

        Persona:
        {persona_text}

        Channel:
        {channel}

        Variants:
        {variants}

        Return JSON with:
        [
        {{
        "variant": "...",
        "score": 0-100,
        "reason": "..."
        }}]
        """
        logger.info(f"Prompt sent to agent:\n{prompt}")
        response = invoke(prompt)

        if not response:
            return {
                "persona": persona_text,
                "channel": channel,
                "variants_scored": [],
                "best_variant": None,
                "error": "No evaluation generated by LLM"
            }

        logger.info(f"LLM Response: \n{response}")

        # JSON Parsing
        try:
            result = json.loads(response)
        except json.JSONDecodeError:
            logger.error("Agent did not return valid JSON. Wrapping fallback.")
            results = [{"variant": v, "score": 0, "reason": "invalid JSON"} for v in variants]

        for r in results:
            try:
                r["score"] = min(max(int(r["score"]), 0), 100)
            except Exception:
                r["score"] = 0

        results_sorted = sorted(
            results,
            key=lambda x: x["score"],
            reverse=True
            )
        best_result = results_sorted[0]
        # Save experiment vectors into the Vectordb
        add_document(
            str(results_sorted)
            metadata={
                "type": "experiment",
                "channel": channel,
                "persona": persona_text
            }
        )

        logger.info("Experiment results stored successfully.")
        return {
            "persona": persona_text,
            "channel": channel,
            "variants_scored": results_sorted,
            "best_variant": best_result
        }
